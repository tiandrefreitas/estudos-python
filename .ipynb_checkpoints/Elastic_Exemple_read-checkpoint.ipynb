{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurar as variáveis de ambiente\n",
    "import os\n",
    "import elasticsearch\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    " \n",
    "# tornar o pyspark \"importável\"\n",
    "import findspark\n",
    "findspark.init('../../../anaconda3/spark-2.4.4-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iniciar uma sessão local\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.window import Window as w\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "            .master(\"local\") \\\n",
    "            .appName(\"Test Elastic\") \\\n",
    "            .config('spark.driver.extraClassPath', '../../../anaconda3/spark-2.4.4-bin-hadoop2.7/elasticsearch-hadoop-2.1.0.Beta3.jar') \\\n",
    "            .getOrCreate()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch([{'host':'localhost','port':9200}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "newAPIHadoopRDD() missing 1 required positional argument: 'keyClass'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-cb567eaa884f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0minputFormatClass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"org.elasticsearch.hadoop.mr.EsInputFormat\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mvalueClass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"org.elasticsearch.hadoop.mr.LinkedMapWritable\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     conf=es_read_conf)\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mes_rdd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: newAPIHadoopRDD() missing 1 required positional argument: 'keyClass'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "q =\"\"\"{\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"must\": [\n",
    "        {\n",
    "          \"wildcard\": {\n",
    "            \"nome_do_assinante\": \"maria*\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\"\"\"\n",
    "\n",
    "es_read_conf = {\n",
    "    \"es.nodes\" : \"localhost\",\n",
    "    \"es.port\" : \"9200\",\n",
    "    \"es.resource\" : \"andre_elk/_doc\",\n",
    "    \"es.index_read_missing_as_empty\" : \"true\",\n",
    "    \"es.query\" : q\n",
    "}\n",
    "\n",
    "es_rdd = spark.newAPIHadoopRDD(\n",
    "    inputFormatClass=\"org.elasticsearch.hadoop.mr.EsInputFormat\",\n",
    "    keyClass=\"org.apache.hadoop.io.NullWritable\", \n",
    "    valueClass=\"org.elasticsearch.hadoop.mr.LinkedMapWritable\", \n",
    "    conf=es_read_conf)\n",
    "\n",
    "df=spark.createDataFrame(es_rdd).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
